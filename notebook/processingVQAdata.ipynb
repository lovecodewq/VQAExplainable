{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdeTNidY2Uqt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download VQA v2 data"
      ],
      "metadata": {
        "id": "NhSCXoAXSgQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = {\n",
        "    \"train_images\": \"http://images.cocodataset.org/zips/train2014.zip\",\n",
        "    \"val_images\": \"http://images.cocodataset.org/zips/val2014.zip\",\n",
        "    \"annotations_train\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip\",\n",
        "    \"annotations_val\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip\",\n",
        "    \"questions_train\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\",\n",
        "    \"questions_val\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip\"\n",
        "}\n",
        "\n",
        "data_dir = 'VQA_data'\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    print(f\"Downloading {url}\")\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    with open(save_path, 'wb') as file, tqdm(\n",
        "        desc=save_path,\n",
        "        total=total_size,\n",
        "        unit='B',\n",
        "        unit_scale=True\n",
        "    ) as bar:\n",
        "        for data in response.iter_content(chunk_size=1024):\n",
        "            file.write(data)\n",
        "            bar.update(len(data))\n",
        "    print(f\"Completed: {save_path}\")\n",
        "\n",
        "# Create directory if it doesn't exist, download the data.\n",
        "# Otherwise, don't download.\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "    for key, url in urls.items():\n",
        "        filename = url.split(\"/\")[-1]\n",
        "        save_path = os.path.join(data_dir, filename)\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            download_file(url, save_path)\n",
        "        else:\n",
        "            print(f\"File already exists: {save_path}\")\n",
        "\n",
        "print(\"Dataset is downloaded successfully.\")"
      ],
      "metadata": {
        "id": "0PjaY3UZRsAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the file"
      ],
      "metadata": {
        "id": "KS_IrrRHSnS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_file(zip_path, extract_to):\n",
        "    print(f\"Extracting {zip_path}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Completed: {zip_path}\")\n",
        "\n",
        "image_files = [os.path.join(data_dir, 'train2014.zip'),\n",
        "               os.path.join(data_dir, 'val2014.zip'),\n",
        "               os.path.join(data_dir, 'v2_Annotations_Train_mscoco.zip'),\n",
        "               os.path.join(data_dir, 'v2_Annotations_Val_mscoco.zip'),\n",
        "               os.path.join(data_dir, 'v2_Questions_Train_mscoco.zip'),\n",
        "               os.path.join(data_dir, 'v2_Questions_Val_mscoco.zip')]\n",
        "\n",
        "for image_file in image_files:\n",
        "    unzip_file(image_file, data_dir)"
      ],
      "metadata": {
        "id": "BLkiDxig2ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceda92c4-5429-4a5f-a402-3f54876f32a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting VQA_data/v2_Annotations_Train_mscoco.zip\n",
            "Completed: VQA_data/v2_Annotations_Train_mscoco.zip\n",
            "Extracting VQA_data/v2_Annotations_Val_mscoco.zip\n",
            "Completed: VQA_data/v2_Annotations_Val_mscoco.zip\n",
            "Extracting VQA_data/v2_Questions_Train_mscoco.zip\n",
            "Completed: VQA_data/v2_Questions_Train_mscoco.zip\n",
            "Extracting VQA_data/v2_Questions_Val_mscoco.zip\n",
            "Completed: VQA_data/v2_Questions_Val_mscoco.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get GLOVE pretrained word embedding"
      ],
      "metadata": {
        "id": "c7GjCUkTSpsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file_path = 'glove.6B.50d.txt'\n",
        "glove_zip_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "glove_zip_path = 'glove.6B.zip'\n",
        "\n",
        "if not os.path.exists(glove_file_path):\n",
        "    response = requests.get(glove_zip_url)\n",
        "    with open(glove_zip_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    with zipfile.ZipFile(glove_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "    os.remove(glove_zip_path)\n",
        "\n",
        "def load_glove_embeddings(file_path, embedding_dim=50):\n",
        "    word_embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            word_embeddings[word] = torch.tensor(vector)\n",
        "    return word_embeddings\n",
        "\n",
        "word_embeddings = load_glove_embeddings(glove_file_path)\n",
        "\n",
        "word = \"computer\"\n",
        "w_embedding = word_embeddings.get(word, torch.zeros(50))\n",
        "print(f\"Embedding for '{word}':\\n\", w_embedding)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMSvXucGQmyF",
        "outputId": "ce9a5102-ea0d-462b-9393-ca3d8a95350b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for 'computer':\n",
            " tensor([ 0.0791, -0.8150,  1.7901,  0.9165,  0.1080, -0.5563, -0.8443, -1.4951,\n",
            "         0.1342,  0.6363,  0.3515,  0.2581, -0.5503,  0.5106,  0.3741,  0.1209,\n",
            "        -1.6166,  0.8365,  0.1420, -0.5235,  0.7345,  0.1221, -0.4908,  0.3253,\n",
            "         0.4531, -1.5850, -0.6385, -1.0053,  0.1045, -0.4298,  3.1810, -0.6219,\n",
            "         0.1682, -1.0139,  0.0641,  0.5784, -0.4556,  0.7378,  0.3720, -0.5772,\n",
            "         0.6644,  0.0551,  0.0379,  1.3275,  0.3099,  0.5070,  1.2357,  0.1274,\n",
            "        -0.1143,  0.2071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the largest size of tokens in the question"
      ],
      "metadata": {
        "id": "3GP696DiS0-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def get_max_tokens(questions_file):\n",
        "    with open(questions_file, 'r') as f:\n",
        "        questions_data = json.load(f)['questions']\n",
        "\n",
        "    max_tokens = 0\n",
        "    for question in questions_data:\n",
        "        tokens = question['question'].lower().split()\n",
        "        max_tokens = max(max_tokens, len(tokens))\n",
        "\n",
        "    return max_tokens\n",
        "\n",
        "\n",
        "questions_file_train = 'VQA_data/v2_OpenEnded_mscoco_train2014_questions.json'\n",
        "questions_file_val = 'VQA_data/v2_OpenEnded_mscoco_val2014_questions.json'\n",
        "\n",
        "max_tokens_train = get_max_tokens(questions_file_train)\n",
        "max_tokens_val = get_max_tokens(questions_file_val)\n",
        "\n",
        "print(f\"Max tokens in questions: {max(max_tokens_train, max_tokens_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0gTkhaoO2Bp",
        "outputId": "50e44e5a-1b61-4614-8507-57b5176e16ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max tokens in questions: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process training and validation set"
      ],
      "metadata": {
        "id": "7wRadOzYUuxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file_path = 'glove.6B.50d.txt'\n",
        "glove_zip_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "glove_zip_path = 'glove.6B.zip'\n",
        "\n",
        "if not os.path.exists(glove_file_path):\n",
        "    response = requests.get(glove_zip_url)\n",
        "    with open(glove_zip_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    with zipfile.ZipFile(glove_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "    os.remove(glove_zip_path)\n",
        "\n",
        "def load_glove_embeddings(file_path, embedding_dim=50):\n",
        "    word_embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            word_embeddings[word] = torch.tensor(vector)\n",
        "    return word_embeddings\n",
        "\n",
        "glove = load_glove_embeddings(glove_file_path)\n",
        "\n",
        "def tokenize_question(question):\n",
        "    return question.lower().split()\n",
        "\n",
        "def tokens_to_embeddings(tokens, embedding_model, max_length=23):\n",
        "    embeddings = []\n",
        "    for token in tokens:\n",
        "        embedding = embedding_model.get(token, torch.zeros(50))\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    if len(embeddings) < max_length:\n",
        "        padding = [torch.zeros(50)] * (max_length - len(embeddings))\n",
        "        embeddings.extend(padding)\n",
        "    else:\n",
        "        embeddings = embeddings[:max_length]\n",
        "\n",
        "    return torch.stack(embeddings)\n",
        "\n",
        "def create_answer_idx(train_annotations_file, val_annotations_file):\n",
        "    all_answers = set()\n",
        "    with open(train_annotations_file, 'r') as f:\n",
        "        train_annotations = json.load(f)['annotations']\n",
        "        for annotation in train_annotations:\n",
        "            all_answers.add(annotation['multiple_choice_answer'])\n",
        "\n",
        "    with open(val_annotations_file, 'r') as f:\n",
        "        val_annotations = json.load(f)['annotations']\n",
        "        for annotation in val_annotations:\n",
        "            all_answers.add(annotation['multiple_choice_answer'])\n",
        "\n",
        "    answer_to_idx = {answer: idx for idx, answer in enumerate(sorted(all_answers))}\n",
        "    idx_to_answer = {idx: answer for idx, answer in enumerate(sorted(all_answers))}\n",
        "    return answer_to_idx, idx_to_answer\n",
        "\n",
        "class VQADataset(Dataset):\n",
        "    def __init__(self, img_dir, questions_file, annotations_file, answer_to_idx, transform=None, max_length=23):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "        with open(questions_file, 'r') as f:\n",
        "            self.questions_data = json.load(f)['questions']\n",
        "        with open(annotations_file, 'r') as f:\n",
        "            self.annotations_data = json.load(f)['annotations']\n",
        "        self.answer_to_idx = answer_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.questions_data[idx]['image_id']\n",
        "        if 'train' in self.img_dir:\n",
        "            img_path = os.path.join(self.img_dir, f\"COCO_train2014_{img_id:012d}.jpg\")\n",
        "        else:\n",
        "            img_path = os.path.join(self.img_dir, f\"COCO_val2014_{img_id:012d}.jpg\")\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        question = self.questions_data[idx]['question']\n",
        "        question_tokens = tokenize_question(question)\n",
        "        question_embeddings = tokens_to_embeddings(question_tokens, glove, self.max_length)\n",
        "\n",
        "        answer = self.annotations_data[idx]['multiple_choice_answer']\n",
        "        answer_idx = self.answer_to_idx[answer]\n",
        "\n",
        "        return img, question_embeddings, answer_idx\n",
        "\n",
        "img_dir_train = 'VQA_data/train2014'\n",
        "img_dir_val = 'VQA_data/val2014'\n",
        "questions_file_train = 'VQA_data/v2_OpenEnded_mscoco_train2014_questions.json'\n",
        "annotations_file_train = 'VQA_data/v2_mscoco_train2014_annotations.json'\n",
        "questions_file_val = 'VQA_data/v2_OpenEnded_mscoco_val2014_questions.json'\n",
        "annotations_file_val = 'VQA_data/v2_mscoco_val2014_annotations.json'\n",
        "\n",
        "answer_to_idx, idx_to_answer = create_answer_idx(annotations_file_train, annotations_file_val)\n",
        "\n",
        "train_dataset = VQADataset(\n",
        "    img_dir_train,\n",
        "    questions_file_train,\n",
        "    annotations_file_train,\n",
        "    answer_to_idx,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    max_length=23\n",
        ")\n",
        "\n",
        "val_dataset = VQADataset(\n",
        "    img_dir_val,\n",
        "    questions_file_val,\n",
        "    annotations_file_val,\n",
        "    answer_to_idx,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    max_length=23\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for images, question_embeddings, answers in train_loader:\n",
        "    print(f\"Batch images: {images.shape}\")\n",
        "    print(f\"Batch question embeddings: {question_embeddings.shape}\")\n",
        "    print(f\"Batch answers: {answers.shape}\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CHtc_rImID_",
        "outputId": "18e28d60-5563-414f-b302-4186ea11ba4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch images: torch.Size([32, 3, 224, 224])\n",
            "Batch question embeddings: torch.Size([32, 23, 50])\n",
            "Batch answers: torch.Size([32])\n"
          ]
        }
      ]
    }
  ]
}